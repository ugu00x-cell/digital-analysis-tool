import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
import csv
import datetime
import io
import re
import math
import time
from pdf_report import generate_report_pdf, generate_batch_summary_pdf

# ===== ãƒšãƒ¼ã‚¸è¨­å®š =====
st.set_page_config(page_title="ä¼æ¥­ãƒ‡ã‚¸ã‚¿ãƒ«åˆ†æãƒ„ãƒ¼ãƒ«", page_icon="ğŸ“Š", layout="wide")

# ===== ã‚«ã‚¹ã‚¿ãƒ CSS =====
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700;900&display=swap');
.stApp { font-family: 'Noto Sans JP', sans-serif; }
.main-header { background: linear-gradient(135deg, #0f172a 0%, #1e293b 50%, #334155 100%); color: white; padding: 2rem 2.5rem; border-radius: 16px; margin-bottom: 1.5rem; position: relative; overflow: hidden; }
.main-header::before { content: ''; position: absolute; top: -50%; right: -10%; width: 300px; height: 300px; background: radial-gradient(circle, rgba(56,189,248,0.15) 0%, transparent 70%); border-radius: 50%; }
.main-header h1 { font-size: 1.8rem; font-weight: 900; margin: 0 0 0.5rem 0; }
.main-header p { font-size: 0.95rem; color: #94a3b8; margin: 0; font-weight: 300; }
.score-card { background: white; border-radius: 16px; padding: 1.8rem; text-align: center; box-shadow: 0 1px 3px rgba(0,0,0,0.08), 0 4px 12px rgba(0,0,0,0.04); border: 1px solid #e2e8f0; transition: transform 0.2s ease; }
.score-card:hover { transform: translateY(-2px); box-shadow: 0 4px 16px rgba(0,0,0,0.1); }
.score-card .score-label { font-size: 0.8rem; color: #64748b; font-weight: 500; letter-spacing: 0.08em; margin-bottom: 0.5rem; }
.score-card .score-value { font-size: 2.8rem; font-weight: 900; line-height: 1; margin-bottom: 0.3rem; }
.score-card .score-sub { font-size: 0.85rem; color: #94a3b8; }
.score-s { color: #dc2626; } .score-a { color: #ea580c; } .score-b { color: #d97706; } .score-c { color: #2563eb; } .score-d { color: #16a34a; }
.rank-badge { display: inline-block; font-size: 1.5rem; font-weight: 900; width: 56px; height: 56px; line-height: 56px; text-align: center; border-radius: 12px; margin-bottom: 0.5rem; }
.rank-s { background: linear-gradient(135deg, #fecaca, #fca5a5); color: #dc2626; }
.rank-a { background: linear-gradient(135deg, #fed7aa, #fdba74); color: #ea580c; }
.rank-b { background: linear-gradient(135deg, #fef08a, #fde047); color: #a16207; }
.rank-c { background: linear-gradient(135deg, #bfdbfe, #93c5fd); color: #2563eb; }
.rank-d { background: linear-gradient(135deg, #bbf7d0, #86efac); color: #16a34a; }
.analysis-item { background: white; border-radius: 12px; padding: 1.2rem 1.5rem; margin-bottom: 0.75rem; border: 1px solid #e2e8f0; display: flex; align-items: center; gap: 1rem; }
.analysis-item .item-icon { font-size: 1.3rem; width: 40px; text-align: center; flex-shrink: 0; }
.analysis-item .item-content { flex: 1; }
.analysis-item .item-name { font-size: 0.9rem; font-weight: 700; color: #1e293b; margin-bottom: 4px; }
.analysis-item .item-bar-bg { background: #f1f5f9; height: 8px; border-radius: 4px; overflow: hidden; }
.analysis-item .item-bar-fill { height: 100%; border-radius: 4px; transition: width 0.6s ease; }
.bar-high { background: linear-gradient(90deg, #22c55e, #4ade80); }
.bar-mid { background: linear-gradient(90deg, #f59e0b, #fbbf24); }
.bar-low { background: linear-gradient(90deg, #ef4444, #f87171); }
.analysis-item .item-score { font-size: 0.95rem; font-weight: 700; color: #334155; flex-shrink: 0; min-width: 60px; text-align: right; }
.alert-target { background: linear-gradient(135deg, #fef2f2, #fee2e2); border: 1px solid #fecaca; border-left: 4px solid #dc2626; color: #991b1b; padding: 1rem 1.5rem; border-radius: 0 12px 12px 0; font-weight: 500; margin: 1rem 0; }
.alert-maybe { background: linear-gradient(135deg, #fffbeb, #fef3c7); border: 1px solid #fde68a; border-left: 4px solid #d97706; color: #92400e; padding: 1rem 1.5rem; border-radius: 0 12px 12px 0; font-weight: 500; margin: 1rem 0; }
.alert-safe { background: linear-gradient(135deg, #f0fdf4, #dcfce7); border: 1px solid #bbf7d0; border-left: 4px solid #16a34a; color: #166534; padding: 1rem 1.5rem; border-radius: 0 12px 12px 0; font-weight: 500; margin: 1rem 0; }
.detail-section { background: #f8fafc; border-radius: 12px; padding: 1.5rem; margin-bottom: 1rem; border: 1px solid #e2e8f0; }
.detail-section h4 { font-size: 0.95rem; font-weight: 700; color: #1e293b; margin: 0 0 1rem 0; padding-bottom: 0.5rem; border-bottom: 2px solid #e2e8f0; }
.detail-row { display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid #f1f5f9; font-size: 0.88rem; }
.detail-row:last-child { border-bottom: none; }
.detail-label { color: #64748b; } .detail-value { font-weight: 600; color: #1e293b; }
.check-ok { color: #16a34a; } .check-ng { color: #dc2626; }
.radar-container { display: flex; justify-content: center; margin: 1rem 0; }
.footer { text-align: center; color: #94a3b8; font-size: 0.8rem; padding: 2rem 0 1rem; border-top: 1px solid #e2e8f0; margin-top: 2rem; }
.stTextInput > div > div > input { border-radius: 12px; border: 2px solid #e2e8f0; padding: 0.75rem 1rem; font-size: 1rem; }
.stTextInput > div > div > input:focus { border-color: #38bdf8; box-shadow: 0 0 0 3px rgba(56,189,248,0.15); }
.stButton > button[kind="primary"] { border-radius: 12px; padding: 0.75rem 2rem; font-weight: 700; font-size: 1rem; background: linear-gradient(135deg, #0ea5e9, #0284c7); border: none; }
.stButton > button[kind="primary"]:hover { background: linear-gradient(135deg, #0284c7, #0369a1); }
.batch-summary { background: white; border-radius: 16px; padding: 1.5rem; border: 1px solid #e2e8f0; box-shadow: 0 1px 3px rgba(0,0,0,0.08); margin-bottom: 1rem; }
.batch-summary .summary-number { font-size: 2rem; font-weight: 900; line-height: 1.2; }
.batch-summary .summary-label { font-size: 0.8rem; color: #64748b; font-weight: 500; }
</style>
""", unsafe_allow_html=True)

# ===== å®šæ•° =====
HEADERS_REQ = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
TIMEOUT = 15
SNS_DOMAINS = {"twitter.com":"Twitter/X","x.com":"X","facebook.com":"Facebook","instagram.com":"Instagram","linkedin.com":"LinkedIn","youtube.com":"YouTube","tiktok.com":"TikTok","line.me":"LINE","note.com":"note"}
RECRUIT_KEYWORDS = ["recruit","career","careers","jobs","hiring","æ¡ç”¨","æ±‚äºº","ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ","æ–°å’","ä¸­é€”","entry","joblist","employment"]
CATEGORY_KEYWORDS = {
    "è£½é€ ":["è£½é€ ","å·¥å ´","è£½ä½œæ‰€","ãƒ¡ãƒ¼ã‚«ãƒ¼","manufacturing","factory"],
    "ITãƒ»Web":["ã‚·ã‚¹ãƒ†ãƒ ","ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢","IT","Web","ã‚¢ãƒ—ãƒª","ãƒ‡ã‚¸ã‚¿ãƒ«","tech"],
    "å»ºè¨­ãƒ»ä¸å‹•ç”£":["å»ºè¨­","å»ºç¯‰","ä¸å‹•ç”£","å·¥å‹™åº—","ãƒªãƒ•ã‚©ãƒ¼ãƒ ","housing"],
    "é£²é£Ÿ":["é£²é£Ÿ","ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³","é£Ÿå ‚","ã‚«ãƒ•ã‚§","æ–™ç†","food"],
    "å°å£²":["è²©å£²","ã‚·ãƒ§ãƒƒãƒ—","ã‚¹ãƒˆã‚¢","store","shop","é€šè²©"],
    "åŒ»ç™‚ãƒ»ä»‹è­·":["åŒ»ç™‚","ã‚¯ãƒªãƒ‹ãƒƒã‚¯","ç—…é™¢","ä»‹è­·","ç¦ç¥‰","æ­¯ç§‘"],
    "æ•™è‚²":["æ•™è‚²","å­¦æ ¡","ã‚¹ã‚¯ãƒ¼ãƒ«","å¡¾","å­¦ç¿’","academy"],
    "å£«æ¥­":["ç¨ç†å£«","ä¼šè¨ˆå£«","å¼è­·å£«","å¸æ³•æ›¸å£«","è¡Œæ”¿æ›¸å£«","ç¤¾åŠ´å£«"],
}
SCORE_META = [{"icon":"ğŸ”’"},{"icon":"ğŸ”"},{"icon":"ğŸ“±"},{"icon":"ğŸ“„"},{"icon":"ğŸ“"},{"icon":"âš™ï¸"},{"icon":"ğŸ‘¥"}]

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def normalize_url(url):
    url = url.strip()
    if not url: return ""
    if not url.startswith(("http://","https://")): url = "https://" + url
    if not urlparse(url).path: url += "/"
    return url

def get_page_safely(url):
    try:
        r = requests.get(url, headers=HEADERS_REQ, timeout=TIMEOUT, allow_redirects=True)
        r.raise_for_status()
        if r.encoding and r.encoding.lower() == "iso-8859-1": r.encoding = r.apparent_encoding
        return BeautifulSoup(r.text, "html.parser"), None
    except requests.exceptions.ConnectionError: return None, "æ¥ç¶šã‚¨ãƒ©ãƒ¼"
    except requests.exceptions.Timeout: return None, "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
    except requests.exceptions.HTTPError as e: return None, f"HTTP {e.response.status_code}"
    except requests.exceptions.RequestException as e: return None, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:80]}"

# ===== åˆ†æé–¢æ•°ç¾¤ =====
def check_https(url): return url.startswith("https://")

def analyze_meta_seo(soup):
    r = {"title":"","title_length":0,"description":"","description_length":0,"has_viewport":False,"has_ogp":False,"h1_count":0,"h1_text":"","has_favicon":False,"has_canonical":False}
    t = soup.find("title")
    if t and t.string: r["title"]=t.string.strip(); r["title_length"]=len(r["title"])
    d = soup.find("meta",attrs={"name":"description"})
    if d and d.get("content"): r["description"]=d["content"].strip(); r["description_length"]=len(r["description"])
    r["has_viewport"] = soup.find("meta",attrs={"name":"viewport"}) is not None
    r["has_ogp"] = soup.find("meta",attrs={"property":"og:title"}) is not None
    h1s = soup.find_all("h1"); r["h1_count"]=len(h1s)
    if h1s: r["h1_text"]=h1s[0].get_text(strip=True)[:50]
    r["has_favicon"] = soup.find("link",rel=lambda x:x and "icon" in x) is not None
    r["has_canonical"] = soup.find("link",rel="canonical") is not None
    return r

def analyze_links(soup, base_url):
    all_a = soup.find_all("a",href=True); bd = urlparse(base_url).netloc
    il,el,sns,rf,ru = [],[],{},False,""
    for a in all_a:
        h = a.get("href","").strip()
        if not h or h.startswith(("#","javascript:","mailto:","tel:")): continue
        fu = urljoin(base_url,h); ld = urlparse(fu).netloc.lower()
        if ld==bd or not ld: il.append(fu)
        else: el.append(fu)
        for sd,sn in SNS_DOMAINS.items():
            if sd in ld: sns[sn]=fu; break
        hl,tl = h.lower(), a.get_text(strip=True).lower()
        for kw in RECRUIT_KEYWORDS:
            if kw in hl or kw in tl: rf=True; ru=fu; break
    return {"total_links":len(all_a),"internal_links":len(il),"external_links":len(el),"sns_links":sns,"sns_count":len(sns),"recruit_found":rf,"recruit_url":ru}

def analyze_contact(soup):
    r = {"has_form":False,"has_phone":False,"phone_number":"","has_email_link":False,"has_contact_page":False}
    r["has_form"] = soup.find("form") is not None
    ph = re.findall(r"0\d{1,4}[-â€ãƒ¼]?\d{1,4}[-â€ãƒ¼]?\d{3,4}", soup.get_text())
    if ph: r["has_phone"]=True; r["phone_number"]=ph[0]
    r["has_email_link"] = soup.find("a",href=re.compile(r"^mailto:")) is not None
    for a in soup.find_all("a",href=True):
        ht = (a.get("href","")+a.get_text()).lower()
        if any(w in ht for w in ["å•ã„åˆã‚ã›","ãŠå•åˆã›","contact","inquiry"]): r["has_contact_page"]=True; break
    return r

def detect_category(soup):
    text = soup.get_text().lower(); sc = {}
    for c,kws in CATEGORY_KEYWORDS.items():
        n = sum(1 for k in kws if k.lower() in text)
        if n>0: sc[c]=n
    return max(sc,key=sc.get) if sc else "ãã®ä»–"

def analyze_tech(soup):
    r = {"has_analytics":False,"has_structured_data":False,"image_count":0,"images_without_alt":0}
    ht = str(soup)
    if any(w in ht for w in ["google-analytics","gtag","googletagmanager"]): r["has_analytics"]=True
    if soup.find("script",type="application/ld+json"): r["has_structured_data"]=True
    imgs = soup.find_all("img"); r["image_count"]=len(imgs)
    r["images_without_alt"] = sum(1 for i in imgs if not i.get("alt"))
    return r

# ===== ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° =====
def calculate_score(url, seo, links, contact, tech):
    score=0; details=[]
    p=10 if check_https(url) else 0; score+=p; details.append(("HTTPSå¯¾å¿œ",p,10,"âœ…" if p==10 else "âŒ"))
    s=0
    if 10<=seo["title_length"]<=60: s+=8
    elif seo["title_length"]>0: s+=4
    if 50<=seo["description_length"]<=160: s+=7
    elif seo["description_length"]>0: s+=3
    if seo["has_viewport"]: s+=5
    if seo["h1_count"]==1: s+=3
    elif seo["h1_count"]>1: s+=1
    if seo["has_favicon"]: s+=2
    score+=s; details.append(("SEOåŸºç¤",s,25,"âœ…" if s>=18 else("âš ï¸" if s>=10 else "âŒ")))
    s=min(links["sns_count"]*5,15); score+=s; details.append(("SNSé€£æº",s,15,"âœ…" if s>=10 else("âš ï¸" if s>=5 else "âŒ")))
    s=0
    if links["total_links"]>100: s+=10
    elif links["total_links"]>50: s+=7
    elif links["total_links"]>20: s+=4
    if links["internal_links"]>30: s+=5
    elif links["internal_links"]>10: s+=3
    s=min(s,15); score+=s; details.append(("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å……å®Ÿåº¦",s,15,"âœ…" if s>=10 else("âš ï¸" if s>=5 else "âŒ")))
    s=0
    if contact["has_form"]: s+=6
    if contact["has_phone"]: s+=4
    if contact["has_email_link"]: s+=3
    if contact["has_contact_page"]: s+=2
    s=min(s,15); score+=s; details.append(("å•ã„åˆã‚ã›å°ç·š",s,15,"âœ…" if s>=10 else("âš ï¸" if s>=5 else "âŒ")))
    s=0
    if tech["has_analytics"]: s+=5
    if tech["has_structured_data"]: s+=3
    if seo["has_ogp"]: s+=2
    s=min(s,10); score+=s; details.append(("æŠ€è¡“ãƒ»é‹ç”¨",s,10,"âœ…" if s>=7 else("âš ï¸" if s>=3 else "âŒ")))
    p=10 if links["recruit_found"] else 0; score+=p; details.append(("æ¡ç”¨ãƒšãƒ¼ã‚¸",p,10,"âœ…" if p==10 else "âŒ"))
    return score, details

def judge(score):
    if score<=25: return "S","æœ€å„ªå…ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ","s"
    elif score<=40: return "A","å–¶æ¥­å¯¾è±¡ï¼ˆé«˜ç¢ºåº¦ï¼‰","a"
    elif score<=55: return "B","å–¶æ¥­å¯¾è±¡ï¼ˆä¸­ç¢ºåº¦ï¼‰","b"
    elif score<=70: return "C","è¦æ¤œè¨","c"
    else: return "D","å¯¾è±¡å¤–ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«æˆç†Ÿï¼‰","d"

# ===== SVGãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ =====
def radar_svg(details):
    cats = [{"name":n.replace("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å……å®Ÿåº¦","ã‚³ãƒ³ãƒ†ãƒ³ãƒ„").replace("å•ã„åˆã‚ã›å°ç·š","å•ã„åˆã‚ã›"),"pct":p/m if m>0 else 0} for n,p,m,_ in details]
    n=len(cats); cx,cy,rm=160,160,120; off=-math.pi/2
    grid=""; axes=""; labels=""; pts=[]; dots=""
    for lv in [0.25,0.5,0.75,1.0]:
        grid+=f'<circle cx="{cx}" cy="{cy}" r="{rm*lv}" fill="none" stroke="#e2e8f0" stroke-width="1"/>'
    for i,c in enumerate(cats):
        a=off+(2*math.pi*i/n); x2=cx+rm*math.cos(a); y2=cy+rm*math.sin(a)
        axes+=f'<line x1="{cx}" y1="{cy}" x2="{x2}" y2="{y2}" stroke="#cbd5e1" stroke-width="1"/>'
        lr=rm+28; lx=cx+lr*math.cos(a); ly=cy+lr*math.sin(a)
        anc="middle"
        if math.cos(a)>0.3: anc="start"
        elif math.cos(a)<-0.3: anc="end"
        labels+=f'<text x="{lx}" y="{ly}" text-anchor="{anc}" dominant-baseline="central" fill="#475569" font-size="11" font-weight="500">{c["name"]}</text>'
        r=rm*c["pct"]; x=cx+r*math.cos(a); y=cy+r*math.sin(a)
        pts.append(f"{x},{y}")
        dots+=f'<circle cx="{x}" cy="{y}" r="4" fill="#0ea5e9" stroke="white" stroke-width="2"/>'
    return f'<svg viewBox="0 0 320 320" xmlns="http://www.w3.org/2000/svg" style="max-width:320px;margin:auto;display:block;">{grid}{axes}<polygon points="{" ".join(pts)}" fill="rgba(14,165,233,0.15)" stroke="#0ea5e9" stroke-width="2.5"/>{dots}{labels}</svg>'

# ===== ãƒ¡ã‚¤ãƒ³åˆ†æ =====
def run_analysis(url):
    url=normalize_url(url)
    if not url: return None,"URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    soup,err=get_page_safely(url)
    if err: return None,err
    seo=analyze_meta_seo(soup); lnk=analyze_links(soup,url); cnt=analyze_contact(soup)
    tch=analyze_tech(soup); cat=detect_category(soup); sc,det=calculate_score(url,seo,lnk,cnt,tch)
    rk,rl,rc=judge(sc)
    return {"url":url,"domain":urlparse(url).netloc,"score":sc,"rank":rk,"rank_label":rl,"rank_class":rc,"details":det,"seo":seo,"links":lnk,"contact":cnt,"tech":tch,"category":cat,"analyzed_at":datetime.datetime.now().strftime("%Y-%m-%d %H:%M")},None

# ===== CSVç”Ÿæˆï¼ˆå…±é€šï¼‰ =====
def generate_csv(results):
    buf = io.StringIO()
    fn = ["åˆ†ææ—¥æ™‚","URL","ã‚¹ã‚³ã‚¢","ãƒ©ãƒ³ã‚¯","åˆ¤å®š","æ¥­ç¨®","HTTPS","ã‚¿ã‚¤ãƒˆãƒ«","description","viewport","OGP","H1æ•°","ãƒªãƒ³ã‚¯ç·æ•°","å†…éƒ¨","å¤–éƒ¨","SNSæ•°","SNSä¸€è¦§","æ¡ç”¨","ãƒ•ã‚©ãƒ¼ãƒ ","é›»è©±","ãƒ¡ãƒ¼ãƒ«","Analytics","æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿","ç”»åƒæ•°","altæœªè¨­å®š"]
    w = csv.DictWriter(buf, fieldnames=fn); w.writeheader()
    for r in results:
        w.writerow({
            "åˆ†ææ—¥æ™‚":r["analyzed_at"],"URL":r["url"],"ã‚¹ã‚³ã‚¢":r["score"],"ãƒ©ãƒ³ã‚¯":r["rank"],
            "åˆ¤å®š":r["rank_label"],"æ¥­ç¨®":r["category"],
            "HTTPS":"â—‹" if check_https(r["url"]) else "Ã—","ã‚¿ã‚¤ãƒˆãƒ«":r["seo"]["title"],
            "description":"â—‹" if r["seo"]["description_length"]>0 else "Ã—",
            "viewport":"â—‹" if r["seo"]["has_viewport"] else "Ã—",
            "OGP":"â—‹" if r["seo"]["has_ogp"] else "Ã—","H1æ•°":r["seo"]["h1_count"],
            "ãƒªãƒ³ã‚¯ç·æ•°":r["links"]["total_links"],"å†…éƒ¨":r["links"]["internal_links"],
            "å¤–éƒ¨":r["links"]["external_links"],"SNSæ•°":r["links"]["sns_count"],
            "SNSä¸€è¦§":" / ".join(r["links"]["sns_links"].keys()),
            "æ¡ç”¨":"â—‹" if r["links"]["recruit_found"] else "Ã—",
            "ãƒ•ã‚©ãƒ¼ãƒ ":"â—‹" if r["contact"]["has_form"] else "Ã—","é›»è©±":r["contact"]["phone_number"],
            "ãƒ¡ãƒ¼ãƒ«":"â—‹" if r["contact"]["has_email_link"] else "Ã—",
            "Analytics":"â—‹" if r["tech"]["has_analytics"] else "Ã—",
            "æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿":"â—‹" if r["tech"]["has_structured_data"] else "Ã—",
            "ç”»åƒæ•°":r["tech"]["image_count"],"altæœªè¨­å®š":r["tech"]["images_without_alt"],
        })
    return buf.getvalue()

# ===== ã‚»ãƒƒã‚·ãƒ§ãƒ³ =====
if "results_history" not in st.session_state: st.session_state.results_history=[]
if "batch_results" not in st.session_state: st.session_state.batch_results=[]

# ============================================
#           ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ï¼‰
# ============================================
with st.sidebar:
    st.markdown("### âš™ï¸ ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    mode = st.radio("åˆ†æãƒ¢ãƒ¼ãƒ‰", ["ğŸ” å˜ä½“åˆ†æ", "ğŸ“‹ ä¸€æ‹¬åˆ†æ"], label_visibility="collapsed")
    st.markdown("---")
    st.markdown("#### ğŸ“– ä½¿ã„æ–¹")
    if "å˜ä½“" in mode:
        st.markdown("1. URLã‚’å…¥åŠ›\n2. ã€Œåˆ†æã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯\n3. çµæœã‚’ç¢ºèªãƒ»CSVä¿å­˜")
    else:
        st.markdown("1. URLã‚’å…¥åŠ›æ¬„ã«è²¼ã‚Šä»˜ã‘\nã€€ï¼ˆ1è¡Œ1URLï¼‰\n2. ã¾ãŸã¯CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n3. ã€Œä¸€æ‹¬åˆ†æã€ã‚’ã‚¯ãƒªãƒƒã‚¯\n4. çµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    st.markdown("---")
    st.markdown(f"**åˆ†ææ¸ˆã¿:** {len(st.session_state.results_history)}ä»¶")

# ============================================
#               ãƒ˜ãƒƒãƒ€ãƒ¼
# ============================================
st.markdown("""
<div class="main-header">
    <h1>ğŸ“Š ä¼æ¥­ãƒ‡ã‚¸ã‚¿ãƒ«åˆ†æãƒ„ãƒ¼ãƒ«</h1>
    <p>Webã‚µã‚¤ãƒˆã®ãƒ‡ã‚¸ã‚¿ãƒ«æˆç†Ÿåº¦ã‚’7é …ç›®100ç‚¹æº€ç‚¹ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‚ã‚¹ã‚³ã‚¢ãŒä½ã„ä¼æ¥­ã»ã©Webæ”¹å–„ã®å–¶æ¥­å¯¾è±¡å€™è£œã«ãªã‚Šã¾ã™ã€‚</p>
</div>
""", unsafe_allow_html=True)

# ============================================
#            å˜ä½“åˆ†æãƒ¢ãƒ¼ãƒ‰
# ============================================
if "å˜ä½“" in mode:
    ci,cb=st.columns([4,1])
    with ci: url=st.text_input("URL",placeholder="https://example.co.jp",label_visibility="collapsed")
    with cb: clicked=st.button("ğŸ” åˆ†æã™ã‚‹",type="primary",use_container_width=True)

    if clicked and url:
        with st.spinner("åˆ†æä¸­..."):
            result,error=run_analysis(url)
        if error:
            st.markdown(f'<div class="alert-target">âš ï¸ {error}</div>',unsafe_allow_html=True)
        else:
            st.session_state.results_history.append(result)
            sc=result["score"]; rk=result["rank"]; rc=result["rank_class"]
            st.markdown("<br>",unsafe_allow_html=True)

            c1,c2,c3=st.columns(3)
            with c1: st.markdown(f'<div class="score-card"><div class="score-label">ç·åˆã‚¹ã‚³ã‚¢</div><div class="score-value score-{rc}">{sc}</div><div class="score-sub">/ 100ç‚¹</div></div>',unsafe_allow_html=True)
            with c2: st.markdown(f'<div class="score-card"><div class="score-label">å–¶æ¥­ãƒ©ãƒ³ã‚¯</div><div class="rank-badge rank-{rc}">{rk}</div><div class="score-sub">{result["rank_label"]}</div></div>',unsafe_allow_html=True)
            with c3: st.markdown(f'<div class="score-card"><div class="score-label">æ¨å®šæ¥­ç¨®</div><div class="score-value" style="font-size:1.6rem;color:#1e293b;">{result["category"]}</div><div class="score-sub">{result["domain"]}</div></div>',unsafe_allow_html=True)

            if sc<=40: st.markdown(f'<div class="alert-target">ğŸ¯ <strong>å–¶æ¥­å¯¾è±¡ã§ã™ï¼</strong> ã‚¹ã‚³ã‚¢{sc}ç‚¹ â†’ Webæ”¹å–„ã®ææ¡ˆä½™åœ°ãŒå¤§ãã„ä¼æ¥­ã§ã™</div>',unsafe_allow_html=True)
            elif sc<=55: st.markdown(f'<div class="alert-maybe">âš ï¸ <strong>è¦æ¤œè¨</strong> ã‚¹ã‚³ã‚¢{sc}ç‚¹ â†’ éƒ¨åˆ†çš„ã«æ”¹å–„ææ¡ˆãŒå¯èƒ½ã§ã™</div>',unsafe_allow_html=True)
            else: st.markdown(f'<div class="alert-safe">âœ… <strong>å¯¾è±¡å¤–</strong> ã‚¹ã‚³ã‚¢{sc}ç‚¹ â†’ ãƒ‡ã‚¸ã‚¿ãƒ«æ–½ç­–ãŒå……å®Ÿã—ã¦ã„ã¾ã™</div>',unsafe_allow_html=True)

            st.markdown("<br>",unsafe_allow_html=True)
            cr,ci2=st.columns([1,1])
            with cr:
                st.markdown("#### ğŸ“ˆ ã‚¹ã‚³ã‚¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")
                st.markdown(f'<div class="radar-container">{radar_svg(result["details"])}</div>',unsafe_allow_html=True)
            with ci2:
                st.markdown("#### ğŸ“‹ ã‚¹ã‚³ã‚¢å†…è¨³")
                for i,(nm,pts,mx,_) in enumerate(result["details"]):
                    pct=int(pts/mx*100) if mx>0 else 0
                    bc="bar-high" if pct>=70 else("bar-mid" if pct>=40 else "bar-low")
                    st.markdown(f'<div class="analysis-item"><div class="item-icon">{SCORE_META[i]["icon"]}</div><div class="item-content"><div class="item-name">{nm}</div><div class="item-bar-bg"><div class="item-bar-fill {bc}" style="width:{pct}%"></div></div></div><div class="item-score">{pts}/{mx}</div></div>',unsafe_allow_html=True)

            st.markdown("<br>",unsafe_allow_html=True)
            d1,d2=st.columns(2)
            with d1:
                se=result["seo"]
                st.markdown(f"""<div class="detail-section"><h4>ğŸ” SEOåˆ†æ</h4>
                <div class="detail-row"><span class="detail-label">ã‚¿ã‚¤ãƒˆãƒ«</span><span class="detail-value">{se['title'][:40] or 'ï¼ˆãªã—ï¼‰'}ï¼ˆ{se['title_length']}æ–‡å­—ï¼‰</span></div>
                <div class="detail-row"><span class="detail-label">meta description</span><span class="detail-value">{'âœ…ã‚ã‚Š' if se['description_length']>0 else 'âŒãªã—'}ï¼ˆ{se['description_length']}æ–‡å­—ï¼‰</span></div>
                <div class="detail-row"><span class="detail-label">ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œ</span><span class="detail-value check-{'ok' if se['has_viewport'] else 'ng'}">{'âœ…å¯¾å¿œ' if se['has_viewport'] else 'âŒæœªå¯¾å¿œ'}</span></div>
                <div class="detail-row"><span class="detail-label">OGP</span><span class="detail-value check-{'ok' if se['has_ogp'] else 'ng'}">{'âœ…ã‚ã‚Š' if se['has_ogp'] else 'âŒãªã—'}</span></div>
                <div class="detail-row"><span class="detail-label">H1ã‚¿ã‚°</span><span class="detail-value">{se['h1_count']}å€‹</span></div>
                <div class="detail-row"><span class="detail-label">canonical</span><span class="detail-value check-{'ok' if se['has_canonical'] else 'ng'}">{'âœ…ã‚ã‚Š' if se['has_canonical'] else 'âŒãªã—'}</span></div>
                <div class="detail-row"><span class="detail-label">favicon</span><span class="detail-value check-{'ok' if se['has_favicon'] else 'ng'}">{'âœ…ã‚ã‚Š' if se['has_favicon'] else 'âŒãªã—'}</span></div>
                </div>""",unsafe_allow_html=True)
                tc=result["tech"]; ar=int((tc["image_count"]-tc["images_without_alt"])/tc["image_count"]*100) if tc["image_count"]>0 else 0
                st.markdown(f"""<div class="detail-section"><h4>âš™ï¸ æŠ€è¡“ãƒ»é‹ç”¨</h4>
                <div class="detail-row"><span class="detail-label">Google Analytics</span><span class="detail-value check-{'ok' if tc['has_analytics'] else 'ng'}">{'âœ…å°å…¥æ¸ˆã¿' if tc['has_analytics'] else 'âŒæœªå°å…¥'}</span></div>
                <div class="detail-row"><span class="detail-label">æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿</span><span class="detail-value check-{'ok' if tc['has_structured_data'] else 'ng'}">{'âœ…ã‚ã‚Š' if tc['has_structured_data'] else 'âŒãªã—'}</span></div>
                <div class="detail-row"><span class="detail-label">ç”»åƒæ•°</span><span class="detail-value">{tc['image_count']}æš</span></div>
                <div class="detail-row"><span class="detail-label">altå±æ€§</span><span class="detail-value">{ar}%è¨­å®šæ¸ˆã¿</span></div>
                </div>""",unsafe_allow_html=True)
            with d2:
                lk=result["links"]; sh=""
                if lk["sns_links"]:
                    for nm2,_ in lk["sns_links"].items(): sh+=f'<div class="detail-row"><span class="detail-label">{nm2}</span><span class="detail-value check-ok">âœ…é€£æº</span></div>'
                else: sh='<div class="detail-row"><span class="detail-label">SNS</span><span class="detail-value check-ng">âŒè¦‹ã¤ã‹ã‚‰ãš</span></div>'
                st.markdown(f"""<div class="detail-section"><h4>ğŸ”— ãƒªãƒ³ã‚¯æ§‹é€ </h4>
                <div class="detail-row"><span class="detail-label">ç·ãƒªãƒ³ã‚¯æ•°</span><span class="detail-value">{lk['total_links']}</span></div>
                <div class="detail-row"><span class="detail-label">å†…éƒ¨ãƒªãƒ³ã‚¯</span><span class="detail-value">{lk['internal_links']}</span></div>
                <div class="detail-row"><span class="detail-label">å¤–éƒ¨ãƒªãƒ³ã‚¯</span><span class="detail-value">{lk['external_links']}</span></div>
                {sh}
                <div class="detail-row"><span class="detail-label">æ¡ç”¨ãƒšãƒ¼ã‚¸</span><span class="detail-value check-{'ok' if lk['recruit_found'] else 'ng'}">{'âœ…ã‚ã‚Š' if lk['recruit_found'] else 'âŒãªã—'}</span></div>
                </div>""",unsafe_allow_html=True)
                ct2=result["contact"]
                st.markdown(f"""<div class="detail-section"><h4>ğŸ“ å•ã„åˆã‚ã›å°ç·š</h4>
                <div class="detail-row"><span class="detail-label">ãƒ•ã‚©ãƒ¼ãƒ </span><span class="detail-value check-{'ok' if ct2['has_form'] else 'ng'}">{'âœ…ã‚ã‚Š' if ct2['has_form'] else 'âŒãªã—'}</span></div>
                <div class="detail-row"><span class="detail-label">é›»è©±ç•ªå·</span><span class="detail-value check-{'ok' if ct2['has_phone'] else 'ng'}">{'âœ…'+ct2['phone_number'] if ct2['has_phone'] else 'âŒè¦‹ã¤ã‹ã‚‰ãš'}</span></div>
                <div class="detail-row"><span class="detail-label">ãƒ¡ãƒ¼ãƒ«</span><span class="detail-value check-{'ok' if ct2['has_email_link'] else 'ng'}">{'âœ…ã‚ã‚Š' if ct2['has_email_link'] else 'âŒãªã—'}</span></div>
                <div class="detail-row"><span class="detail-label">å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸</span><span class="detail-value check-{'ok' if ct2['has_contact_page'] else 'ng'}">{'âœ…ã‚ã‚Š' if ct2['has_contact_page'] else 'âŒãªã—'}</span></div>
                </div>""",unsafe_allow_html=True)

            # --- PDFãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
            st.markdown("<br>",unsafe_allow_html=True)
            try:
                pdf_bytes = generate_report_pdf(result)
                st.download_button(
                    "ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=pdf_bytes,
                    file_name=f"report_{result['domain']}_{datetime.datetime.now().strftime('%Y%m%d')}.pdf",
                    mime="application/pdf",
                    type="primary",
                    use_container_width=True,
                )
            except Exception as e:
                st.warning(f"PDFç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.caption("ğŸ’¡ reportlab ãŒå¿…è¦ã§ã™: pip install reportlab")

# ============================================
#            ä¸€æ‹¬åˆ†æãƒ¢ãƒ¼ãƒ‰
# ============================================
elif "ä¸€æ‹¬" in mode:
    st.markdown("### ğŸ“‹ ä¸€æ‹¬åˆ†æ")
    st.markdown("è¤‡æ•°ã®ä¼æ¥­URLã‚’ã¾ã¨ã‚ã¦åˆ†æã—ã¾ã™ã€‚1è¡Œã«1URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # å…¥åŠ›æ–¹æ³•ã®é¸æŠ
    input_method = st.radio("å…¥åŠ›æ–¹æ³•", ["ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ğŸ“ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"], horizontal=True, label_visibility="collapsed")

    urls_to_analyze = []

    if "ãƒ†ã‚­ã‚¹ãƒˆ" in input_method:
        url_text = st.text_area(
            "URLãƒªã‚¹ãƒˆï¼ˆ1è¡Œ1URLï¼‰",
            height=200,
            placeholder="https://example1.co.jp\nhttps://example2.co.jp\nhttps://example3.co.jp"
        )
        if url_text:
            urls_to_analyze = [u.strip() for u in url_text.strip().split("\n") if u.strip()]

    else:
        uploaded = st.file_uploader("URLãŒå«ã¾ã‚Œã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«", type=["csv","txt"])
        if uploaded:
            content = uploaded.read().decode("utf-8-sig")
            lines = content.strip().split("\n")
            for line in lines:
                # CSVã®å„åˆ—ã‚’ãƒã‚§ãƒƒã‚¯ã€URLã£ã½ã„ã‚‚ã®ã‚’æŠ½å‡º
                for cell in line.split(","):
                    cell = cell.strip().strip('"')
                    if cell.startswith(("http://","https://")) or "." in cell:
                        if any(cell.endswith(d) or d+"/" in cell for d in [".jp",".com",".co.jp",".net",".org",".io"]) or cell.startswith("http"):
                            urls_to_analyze.append(cell)
                            break

    if urls_to_analyze:
        st.info(f"ğŸ“Š {len(urls_to_analyze)} ä»¶ã®URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")

        # å¾…ã¡æ™‚é–“ã®ç›®å®‰
        wait_sec = len(urls_to_analyze) * 5
        st.caption(f"â± æ¨å®šæ‰€è¦æ™‚é–“: ç´„{wait_sec//60}åˆ†{wait_sec%60}ç§’ï¼ˆ1ä»¶ã‚ãŸã‚Šç´„5ç§’ï¼‰")

    batch_clicked = st.button("ğŸš€ ä¸€æ‹¬åˆ†æã‚’é–‹å§‹", type="primary", use_container_width=True, disabled=len(urls_to_analyze)==0)

    if batch_clicked and urls_to_analyze:
        st.session_state.batch_results = []
        errors = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        results_container = st.empty()

        for i, u in enumerate(urls_to_analyze):
            status_text.markdown(f"**åˆ†æä¸­:** {u} ï¼ˆ{i+1}/{len(urls_to_analyze)}ï¼‰")
            progress_bar.progress((i) / len(urls_to_analyze))

            result, error = run_analysis(u)
            if error:
                errors.append({"url": u, "error": error})
            else:
                st.session_state.batch_results.append(result)
                st.session_state.results_history.append(result)

            # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚ã®å¾…æ©Ÿ
            if i < len(urls_to_analyze) - 1:
                time.sleep(1)

        progress_bar.progress(1.0)
        status_text.markdown("**âœ… åˆ†æå®Œäº†ï¼**")

        if errors:
            st.warning(f"âš ï¸ {len(errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                for e in errors:
                    st.write(f"- {e['url']}: {e['error']}")

    # ä¸€æ‹¬åˆ†æçµæœã®è¡¨ç¤º
    if st.session_state.batch_results:
        br = st.session_state.batch_results
        st.markdown("---")
        st.markdown(f"### ğŸ“Š ä¸€æ‹¬åˆ†æçµæœï¼ˆ{len(br)}ä»¶ï¼‰")

        # ã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰
        targets = [r for r in br if r["score"] <= 40]
        maybes = [r for r in br if 40 < r["score"] <= 55]
        safes = [r for r in br if r["score"] > 55]
        avg_score = sum(r["score"] for r in br) / len(br) if br else 0

        s1,s2,s3,s4 = st.columns(4)
        with s1:
            st.markdown(f'<div class="batch-summary" style="text-align:center;"><div class="summary-number" style="color:#dc2626;">{len(targets)}</div><div class="summary-label">ğŸ¯ å–¶æ¥­å¯¾è±¡</div></div>',unsafe_allow_html=True)
        with s2:
            st.markdown(f'<div class="batch-summary" style="text-align:center;"><div class="summary-number" style="color:#d97706;">{len(maybes)}</div><div class="summary-label">âš ï¸ è¦æ¤œè¨</div></div>',unsafe_allow_html=True)
        with s3:
            st.markdown(f'<div class="batch-summary" style="text-align:center;"><div class="summary-number" style="color:#16a34a;">{len(safes)}</div><div class="summary-label">âœ… å¯¾è±¡å¤–</div></div>',unsafe_allow_html=True)
        with s4:
            st.markdown(f'<div class="batch-summary" style="text-align:center;"><div class="summary-number" style="color:#2563eb;">{avg_score:.0f}</div><div class="summary-label">ğŸ“Š å¹³å‡ã‚¹ã‚³ã‚¢</div></div>',unsafe_allow_html=True)

        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆã‚¹ã‚³ã‚¢æ˜‡é †ï¼å–¶æ¥­å¯¾è±¡ãŒä¸Šï¼‰
        sorted_results = sorted(br, key=lambda x: x["score"])
        table_data = []
        for r in sorted_results:
            table_data.append({
                "ãƒ©ãƒ³ã‚¯": r["rank"],
                "ã‚¹ã‚³ã‚¢": r["score"],
                "URL": r["domain"],
                "åˆ¤å®š": r["rank_label"],
                "æ¥­ç¨®": r["category"],
                "HTTPS": "âœ…" if check_https(r["url"]) else "âŒ",
                "SNS": r["links"]["sns_count"],
                "æ¡ç”¨": "âœ…" if r["links"]["recruit_found"] else "âŒ",
                "é›»è©±": "âœ…" if r["contact"]["has_phone"] else "âŒ",
            })
        st.dataframe(table_data, use_container_width=True, hide_index=True)

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv_data = generate_csv(sorted_results)
        dl1, dl2 = st.columns(2)
        with dl1:
            st.download_button(
                "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"batch_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                type="primary",
                use_container_width=True,
            )
        with dl2:
            try:
                batch_pdf = generate_batch_summary_pdf(sorted_results)
                st.download_button(
                    "ğŸ“„ PDFã‚µãƒãƒªãƒ¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=batch_pdf,
                    file_name=f"batch_summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                    mime="application/pdf",
                    type="primary",
                    use_container_width=True,
                )
            except Exception as e:
                st.warning(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ—‘ï¸ ä¸€æ‹¬åˆ†æçµæœã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.batch_results = []
            st.rerun()

# ============================================
#         å±¥æ­´ï¼ˆå˜ä½“åˆ†æãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ï¼‰
# ============================================
if "å˜ä½“" in mode and st.session_state.results_history:
    st.markdown("<br>",unsafe_allow_html=True)
    st.markdown("---")
    st.markdown(f"### ğŸ“ åˆ†æå±¥æ­´ï¼ˆ{len(st.session_state.results_history)}ä»¶ï¼‰")
    hd = [{"æ—¥æ™‚":r["analyzed_at"],"URL":r["domain"],"ã‚¹ã‚³ã‚¢":r["score"],"ãƒ©ãƒ³ã‚¯":r["rank"],"åˆ¤å®š":r["rank_label"],"æ¥­ç¨®":r["category"],"SNS":r["links"]["sns_count"],"æ¡ç”¨":"âœ…" if r["links"]["recruit_found"] else "âŒ"} for r in st.session_state.results_history]
    st.dataframe(hd, use_container_width=True, hide_index=True)
    csv_data = generate_csv(st.session_state.results_history)
    cd,cc = st.columns([1,1])
    with cd:
        st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data,
            file_name=f"analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv", type="primary", use_container_width=True)
    with cc:
        if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.results_history = []
            st.rerun()

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown('<div class="footer">ä¼æ¥­ãƒ‡ã‚¸ã‚¿ãƒ«åˆ†æãƒ„ãƒ¼ãƒ« v4.0 | Built with Streamlit + Python</div>', unsafe_allow_html=True)
